{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "PATH = './cut_imgs/insulator/'\n",
    "\n",
    "\n",
    "def crop_images():\n",
    "    \n",
    "    os.mkdir(PATH + 'reshaped')\n",
    "    files = os.listdir(PATH)\n",
    "\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            image = Image.open(PATH + file_name)\n",
    "            new_img = image.resize((64, 64))\n",
    "            new_img.save(PATH + 'reshaped/' + file_name[:-4] + '.jpg')\n",
    "\n",
    "\n",
    "\n",
    "crop_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsulatorDataset(Dataset):\n",
    "    \"\"\"Insulator dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        files = os.listdir(root_dir)\n",
    "\n",
    "        \n",
    "        self.imgs = []\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.jpg'):\n",
    "                self.imgs.append(file_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_dir, self.imgs[idx])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = InsulatorDataset(root_dir='cut_imgs/insulator/reshaped',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.Grayscale(),\n",
    "                                               transforms.RandomCrop(64),\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.RandomPerspective(),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]))\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(Autoencoder,self).__init__()\n",
    "\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(3, 6, kernel_size=5),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Conv2d(6,16,kernel_size=5),\n",
    "#             nn.ReLU(True))\n",
    "#         self.decoder = nn.Sequential(             \n",
    "#             nn.ConvTranspose2d(16,6,kernel_size=5),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(6,3,kernel_size=5),\n",
    "#             nn.ReLU(True))\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 16,kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 16,kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16,16,kernel_size=5),\n",
    "            nn.ConvTranspose2d(16, 16, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16,6,kernel_size=5),\n",
    "            nn.ConvTranspose2d(6, 6, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(6,1,kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def shit(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().cpu()\n",
    "distance = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining some params\n",
    "num_epochs = 100 #you can go for more epochs, I am using a mac\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.0038\n",
      "epoch [2/100], loss:0.0025\n",
      "epoch [3/100], loss:0.0040\n",
      "epoch [4/100], loss:0.0040\n",
      "epoch [5/100], loss:0.0047\n",
      "epoch [6/100], loss:0.0031\n",
      "epoch [7/100], loss:0.0043\n",
      "epoch [8/100], loss:0.0039\n",
      "epoch [9/100], loss:0.0028\n",
      "epoch [10/100], loss:0.0053\n",
      "epoch [11/100], loss:0.0034\n",
      "epoch [12/100], loss:0.0035\n",
      "epoch [13/100], loss:0.0037\n",
      "epoch [14/100], loss:0.0029\n",
      "epoch [15/100], loss:0.0035\n",
      "epoch [16/100], loss:0.0036\n",
      "epoch [17/100], loss:0.0020\n",
      "epoch [18/100], loss:0.0037\n",
      "epoch [19/100], loss:0.0039\n",
      "epoch [20/100], loss:0.0032\n",
      "epoch [21/100], loss:0.0038\n",
      "epoch [22/100], loss:0.0025\n",
      "epoch [23/100], loss:0.0023\n",
      "epoch [24/100], loss:0.0039\n",
      "epoch [25/100], loss:0.0022\n",
      "epoch [26/100], loss:0.0038\n",
      "epoch [27/100], loss:0.0033\n",
      "epoch [28/100], loss:0.0045\n",
      "epoch [29/100], loss:0.0040\n",
      "epoch [30/100], loss:0.0030\n",
      "epoch [31/100], loss:0.0032\n",
      "epoch [32/100], loss:0.0030\n",
      "epoch [33/100], loss:0.0031\n",
      "epoch [34/100], loss:0.0031\n",
      "epoch [35/100], loss:0.0030\n",
      "epoch [36/100], loss:0.0031\n",
      "epoch [37/100], loss:0.0032\n",
      "epoch [38/100], loss:0.0037\n",
      "epoch [39/100], loss:0.0037\n",
      "epoch [40/100], loss:0.0041\n",
      "epoch [41/100], loss:0.0036\n",
      "epoch [42/100], loss:0.0031\n",
      "epoch [43/100], loss:0.0051\n",
      "epoch [44/100], loss:0.0040\n",
      "epoch [45/100], loss:0.0032\n",
      "epoch [46/100], loss:0.0033\n",
      "epoch [47/100], loss:0.0021\n",
      "epoch [48/100], loss:0.0018\n",
      "epoch [49/100], loss:0.0041\n",
      "epoch [50/100], loss:0.0028\n",
      "epoch [51/100], loss:0.0044\n",
      "epoch [52/100], loss:0.0036\n",
      "epoch [53/100], loss:0.0035\n",
      "epoch [54/100], loss:0.0044\n",
      "epoch [55/100], loss:0.0027\n",
      "epoch [56/100], loss:0.0053\n",
      "epoch [57/100], loss:0.0028\n",
      "epoch [58/100], loss:0.0041\n",
      "epoch [59/100], loss:0.0028\n",
      "epoch [60/100], loss:0.0031\n",
      "epoch [61/100], loss:0.0033\n",
      "epoch [62/100], loss:0.0035\n",
      "epoch [63/100], loss:0.0017\n",
      "epoch [64/100], loss:0.0042\n",
      "epoch [65/100], loss:0.0030\n",
      "epoch [66/100], loss:0.0034\n",
      "epoch [67/100], loss:0.0030\n",
      "epoch [68/100], loss:0.0028\n",
      "epoch [69/100], loss:0.0027\n",
      "epoch [70/100], loss:0.0040\n",
      "epoch [71/100], loss:0.0025\n",
      "epoch [72/100], loss:0.0032\n",
      "epoch [73/100], loss:0.0020\n",
      "epoch [74/100], loss:0.0042\n",
      "epoch [75/100], loss:0.0037\n",
      "epoch [76/100], loss:0.0032\n",
      "epoch [77/100], loss:0.0024\n",
      "epoch [78/100], loss:0.0030\n",
      "epoch [79/100], loss:0.0028\n",
      "epoch [80/100], loss:0.0030\n",
      "epoch [81/100], loss:0.0027\n",
      "epoch [82/100], loss:0.0020\n",
      "epoch [83/100], loss:0.0025\n",
      "epoch [84/100], loss:0.0027\n",
      "epoch [85/100], loss:0.0025\n",
      "epoch [86/100], loss:0.0017\n",
      "epoch [87/100], loss:0.0031\n",
      "epoch [88/100], loss:0.0025\n",
      "epoch [89/100], loss:0.0049\n",
      "epoch [90/100], loss:0.0047\n",
      "epoch [91/100], loss:0.0027\n",
      "epoch [92/100], loss:0.0038\n",
      "epoch [93/100], loss:0.0028\n",
      "epoch [94/100], loss:0.0017\n",
      "epoch [95/100], loss:0.0030\n",
      "epoch [96/100], loss:0.0031\n",
      "epoch [97/100], loss:0.0025\n",
      "epoch [98/100], loss:0.0039\n",
      "epoch [99/100], loss:0.0044\n",
      "epoch [100/100], loss:0.0026\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img = data\n",
    "        img = Variable(img).cpu()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = distance(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = InsulatorDataset(\"cut_imgs/insulator/reshaped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "conversion from RGB to A not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdither\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: conversion from RGB to A not supported",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-c3ec6e53d2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m145\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0;31m# normalize source image and try again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodebase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdither\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"illegal conversion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: conversion from RGB to A not supported"
     ]
    }
   ],
   "source": [
    "transforms.ToTensor()(ds[145].convert('A')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(Variable(torch.reshape(transform(ds[145]), (1, 1, 64, 64))).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = model(Variable(torch.reshape(transforms.ToTensor()(ds[145].cone), (1, 1, 64, 64))).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x7F8538C56240>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.ToPILImage()(a[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    #print(data.shape)\n",
    "    img = Variable(data).cpu()\n",
    "    plt.imshow(transforms.ToPILImage()(img[0, :, :, :]))\n",
    "#     print(img.shape)\n",
    "#     output = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"hahaha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/artembakhanov/Code/hackatons/cifr2020'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ConvTranspose2d(6, 6, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(6, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = torch.load(\"hahaha\")\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "img should be PIL Image. Got <class '__main__.InsulatorDataset'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-322d90536baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomly\u001b[0m \u001b[0mgrayscaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \"\"\"\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_output_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_grayscale\u001b[0;34m(img, num_output_channels)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \"\"\"\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_output_channels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: img should be PIL Image. Got <class '__main__.InsulatorDataset'>"
     ]
    }
   ],
   "source": [
    "a = model1(Variable(torch.reshape(transform(ds), (1, 1, 64, 64))).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x7F8529DEE710>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.ToPILImage()(a[0, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation forest for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_dataset = InsulatorDataset(root_dir='cut_imgs/insulator/reshaped',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.Grayscale(),\n",
    "                                               transforms.RandomCrop(64),\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.RandomPerspective(),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]))\n",
    "anomaly_dataloader = DataLoader(transformed_dataset, batch_size=1,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "a = []\n",
    "for data in anomaly_dataloader:\n",
    "    img = data\n",
    "    img = Variable(img).cpu()\n",
    "    output = model.shit(img)\n",
    "    im = output[0, :, :, :].detach().numpy().reshape(-1)\n",
    "    a.append(im)\n",
    "#     im.save(f\"insulator_anomaly_dataset/img/{str(i).zfill(4)}.jpg\")\n",
    "    i += 1\n",
    "    \n",
    "a = np.array(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 1296)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(n_estimators=20, warm_start=True)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = IsolationForest(n_estimators=10, warm_start=True)\n",
    "clf.fit(a)\n",
    "clf.set_params(n_estimators=20)\n",
    "clf.fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.random.rand(1, 1296))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(a[123, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.dumps(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"anomaly.model\", \"bw\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"anomaly.model\", \"br\") as f:\n",
    "    modelka = f.read()\n",
    "    clf_load = pickle.loads(modelka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_load.predict(a[346, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"anomaly_dataset_np.set\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
