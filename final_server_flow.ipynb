{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yolov4 in /opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages (from yolov4) (1.18.2)\n",
      "Requirement already satisfied: easydict in /opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages (from yolov4) (1.9)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install yolov4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov4.tf import YOLOv4\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillar_yolo = YOLOv4()\n",
    "\n",
    "pillar_yolo.classes = \"pillar.names\"\n",
    "\n",
    "pillar_yolo.make_model()\n",
    "pillar_yolo.load_weights(\"pillar.weights\", weights_type=\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "insulator_yolo = YOLOv4()\n",
    "\n",
    "insulator_yolo.classes = \"insulator.names\"\n",
    "\n",
    "insulator_yolo.make_model()\n",
    "insulator_yolo.load_weights(\"insulator.weights\", weights_type=\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ConvTranspose2d(6, 6, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(6, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 16,kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 16,kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16,16,kernel_size=5),\n",
    "            nn.ConvTranspose2d(16, 16, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16,6,kernel_size=5),\n",
    "            nn.ConvTranspose2d(6, 6, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(6,1,kernel_size=5),\n",
    "            nn.ReLU(True))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def shit(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "encoder = torch.load(\"encoder.model\")\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"anomaly.model\", \"br\") as f:\n",
    "    anomaly_model = f.read()\n",
    "    anomaly_model = pickle.loads(anomaly_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"example.jpg\")\n",
    "bb = pillar_yolo.predict(np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])\n",
    "\n",
    "def get_broken_insulators(img, pillar_bb):\n",
    "    width, height = img.size\n",
    "    x1 = (width * (float(pillar_bb[0]) - float(pillar_bb[2]) / 2))\n",
    "    y1 = (height * (float(pillar_bb[1]) - float(pillar_bb[3]) / 2))\n",
    "    x2 = (width * (float(pillar_bb[0]) + float(pillar_bb[2]) / 2))\n",
    "    y2 = (height * (float(pillar_bb[1]) + float(pillar_bb[3]) / 2))\n",
    "    pillar = img.crop((x1, y1, x2, y2))\n",
    "    \n",
    "    pred = insulator_yolo.predict(np.array(pillar))\n",
    "    broken = []\n",
    "    for bb in pred:\n",
    "        width, height = pillar.size\n",
    "        x1 = (width * (float(bb[0]) - float(bb[2]) / 2))\n",
    "        y1 = (height * (float(bb[1]) - float(bb[3]) / 2))\n",
    "        x2 = (width * (float(bb[0]) + float(bb[2]) / 2))\n",
    "        y2 = (height * (float(bb[1]) + float(bb[3]) / 2))\n",
    "        insul = pillar.crop((x1, y1, x2, y2))\n",
    "        insul = insul.resize((64, 64))\n",
    "        encoded = encoder.shit(Variable(torch.reshape(transform(insul), (1, 1, 64, 64))).cpu())\n",
    "        output = encoded[0, :, :, :].detach().numpy().reshape(1, -1)\n",
    "        \n",
    "        is_broken = anomaly_model.predict(output)\n",
    "        if is_broken[0] == -1:\n",
    "            broken.append(pillar.crop((x1, y1, x2, y2)))\n",
    "    return broken\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3fec3d922a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_broken_insulators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-e24ee7c631e6>\u001b[0m in \u001b[0;36mget_broken_insulators\u001b[0;34m(img, pillar_bb)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpillar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsulator_yolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpillar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbroken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/yolov4/tf/__init__.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, frame, iou_threshold, score_threshold)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# image_data == Dim(1, input_szie, input_size, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_data\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/yolov4/common/base_class.py\u001b[0m in \u001b[0;36mresize_image\u001b[0;34m(self, image, ground_truth)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m    169\u001b[0m         return media.resize_image(\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TensorFlowSpecific/lib/python3.6/site-packages/yolov4/common/media.py\u001b[0m in \u001b[0;36mresize_image\u001b[0;34m(image, target_size, ground_truth)\u001b[0m\n\u001b[1;32m     58\u001b[0m                                                                 ground_truth)\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "a = get_broken_insulators(im, bb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"broken2.JPG\")\n",
    "bb = pillar_yolo.predict(np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_broken_insulators(im, bb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb7fcb21fd0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPMAAAD8CAYAAACioJLqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHUhJREFUeJztnXuIZnd5x7/PeS9z352d7CXb7OZm0orYmkIalEprYy2pFKIgoqUlhdBYqFRbKaZS0IpCCmoqVCxa06zQGsVLE4q9hFSwljYaNY1JNm1iTMxu9pK9zs71vT394z2Jkz3fZ+Y9c2be2f35/cCyM8/85nd+5/LMmfme53wfc3cIIS5+sq1egBBiY1AyC5EISmYhEkHJLEQiKJmFSAQlsxCJoGQWIhGUzEIkgpJZiESoV/lmM7sJwCcB1AD8rbvfsdr48fEJ3z69oxD/aa5BK1OBZ2abNne8TRqtPO9GQfcxOE7RqsPjSsJlz0Gpizs4X0eeP3TC3Xet9e3rTmYzqwH4FIA3ATgE4Dtmdp+7Px59z/bpHbjlXX9UiLMTEh2D6GCWuXCjsVmJE+W9gYeuSqfTKcZ6XTq20WiUmpse12Dh0XFl8fiCHnwOAMiywX8xZMcJADpkf6J5a7UajdfrPA1qteI80diQLr/Wej1yHnp87Ef+/I+fHWRTVX7NvgHAU+7+tLu3ANwD4OYK8wkhKlAlmS8D8NyKzw/lsZdhZreZ2UNm9tDCwnyFzQkhVmPTBTB3/4y7X+/u14+PT2z25oT4qaVKMh8GsH/F5/vymBBiC6iiZn8HwLVmdhX6SfwOAL+96nfY4GrgZuqlkUASCmNsfPBjsBcIHmXmbgbrs6yc+Mfm7uuWg8+xEWyEYh/FG2x/iHC12jra7RaNd7vFeVotPjYS16IrubYJV/i6k9ndO2b2bgD/iv6jqbvc/bENW5kQohSVnjO7+9cBfH2D1iKEqIAqwIRIBCWzEIlQ6dfs0jgXIcqUyIViT4nqI1p9g1h0i8YzPKhdi8QrFo2ORzdad0nRqAxlKsBioSuqguKVbmXmYGuJ7lC9YH3R+e11Bz/vFlRvheeSxKtqkLozC5EISmYhEkHJLEQiKJmFSAQlsxCJMFQ121FdzY7oRW9A05fXS85N1M6yJaGRkkrV9g0qrdxM44ONmKPMtVBGQY/2u+x71WyecGygiIdngKrZ1c677sxCJIKSWYhEUDILkQhKZiESQcksRCIMtzYbgVK7iS+vl6mrji1XB1ecy+qR7KX2UBHv8lrmMtssW1ddRnGOXtAvc27KKuIbUTse1uqXeWcgiEeOr0wVL3Ot0jkrfbcQ4oJBySxEIiiZhUgEJbMQiVC119QzAM4B6ALouPv1G7EoIUR5NkLN/jV3PzHoYKYQbqbNK1MII9U1awQ9h5hi6lxZLluzbbTvWeBO0S2pRJPh3iun+pc5N6EqnAVzkJ0veyXQYxU2jivXg6pM3Xd03iM1u1wPr8HQr9lCJELVZHYA/2Zm3zWz2zZiQUKI9VH11+zXu/thM9sN4H4ze8Ldv7lyQJ7ktwHAtu3TFTcnhIiodGd298P5/8cBfA39Nq/nj3mpcdyYGscJsWlUabY+ASBz93P5x78B4MNrfh+qlax5YGnKxB4A6BGhygIRg/YtAlCvF+Ojo+N8bMbnOHv2LI07sXNtjozQsWVLVlm8a+VKF5vNJo0z2p1lGu92Bt9mmQbsEXHZZpvGM+NpUEaQikaWMUqI7KIHpcqv2XsAfC1fVB3AP7j7v1RajRBi3VRpHPc0gNds4FqEEBXQoykhEkHJLEQiKJmFSIThmhMYANJAjSm6bBwAtCMxPKgD7BKFsNNt8bkXuRo7Qsr9eu1FOnZpfoHGT518gca9U1TbJyb4I7xIQY/KUHvkGIbPEgIlf3xiim2Rjl06s0TjUUWoOym1bQaKbnA9jDQahVik7kd3LiPrACIb5HJPYyw4rpRgHwf+9krfLYS4YFAyC5EISmYhEkHJLEQiKJmFSIThqtkOdNkL3/Ql+mCKkoJfkyi9nTav0e225mn81Llzhdjs2dN07MJscSwAzAXxLrHPHR/ltdmTE9tpvBmo3M0xEq8X1d/+2DG+TTJ3s8kV2l6XH9eIepMo0VEtM4JtlqhnDo0WgnCZhoGxvW+kfpdQuQdEd2YhEkHJLEQiKJmFSAQlsxCJoGQWIhGGXpvNbE2XWkUVNAvqVDOL7FKD2t1mcfz8Mq/BPv3CURo/dbwYP33iGB3bafG67267Q+PtdlHNnq/x03KmfpLGa4EbyOgYqasO1OxGc5TGF04XHVJGAuW70+P2w7v27KXxSWIjdW6R17YzS2KAH9fQ3SO0Gebnhl2rYd13SYcUJw44WVYtHXVnFiIRlMxCJIKSWYhEUDILkQhr/sVtZncB+C0Ax9391XlsBsAXAVwJ4BkAb3d3Xt+4gswyNInQMr9YfKk9ErRGI+vXHheeFmZnC7GzJ4/TsccOP0vjJ4nYVYteaOeri9ofodksngIPalaX2nwfe4GgNz9XjHt4yvk2jx0uin8NYggAANt38CYHjUC0bJN1d4OxY+OTfG5Srhv1jorEq1boeFEk7OtVwlI3npsLiIMyyJ35bgA3nRe7HcAD7n4tgAfyz4UQW8iayZy3mzl1XvhmAAfyjw8AeMsGr0sIUZL1/s28x92P5B8fRd8Qn2Jmt5nZQ2b20Pz83Do3J4RYi8oCmPf/WAjb6q7sNTUxwf/uEUJUZ73JfMzM9gJA/j9XlIQQQ2O99WP3AbgFwB35//cO9F0G1BrFnx8T40WFmqm8ANAMyjyPHuE/T04ee74Qmz11go5dnOMGAiO14pqj0ruFBW432wsa3tVrRXXfAkXXA8XZglLCTquojkalixEZMU/odfgcZ7o8vhD8eTVKLIW377iEjp3euYvGd1yysxibmaFjo8Z27U5Q5kksoGMTgvCXUwqbp9stN8f5rHlnNrMvAPgvAD9nZofM7Fb0k/hNZvYkgF/PPxdCbCFr3pnd/Z3Bl964wWsRQlRAFWBCJIKSWYhEUDILkQjDNSeAw4maunt3UcEcbXDVMKqrnj3BjQWeOvhYITY/W3zhHgCmJrllbb1erPVdnOeq9ekzZ2i8lnH7XFZq7r1AnQ7U7KihHBsfqa6NoJ6Z1TlHxhGtZd5Mb36ePyWYP/TjQiyqwb503z4a33tZMd5pcdV6YorPHTXqY8YHS0tRc7ywKj8YT0aWqONm6M4sRCIomYVIBCWzEImgZBYiEZTMQiTCUNXsTruDU8eLrh295aLKaD3ehOzY89wN5FRgk3uSbK+1xOeuZ9xBw73o8LEUKKZLi7w+2QOv2BFiLtHpBHauNa6IRz+TmTpqFjQsC5xdPGNr4WNZ3T0AZIG9b5ec4+UlbrU7e+r8V+pjIkeRvfsvp/GJyW00nlkxPVrEGnm1bZZxJomeKAyK7sxCJIKSWYhEUDILkQhKZiESYagC2MLcHB76z/8uxCfGijWNjQYXFLrBC+azJ7nTb0Y61I+PcyGpRV7mB4AeKdXrOv85WA9KKyOYyUEzEJKiksFeh6+blgdSQQtoBaKbEeEui0oUwdcRWd+OjhJTiuD+0nMuLM6eKZ53C3p1WY0LcZEoODpZLPOsNfkcIP3SAKATGDmwc1PNmkB3ZiGSQcksRCIomYVIBCWzEIkwiKHfXWZ23MweXRH7kJkdNrOH839v3txlCiHWYhA1+24Afw3g8+fF73T3j5XZ2OLiEh57+PFCfNtEUdW8ZIa/SD42wpfcbgclmnWiXAdKdDtQHrvEbhbEfhcARhpF69zVtskE6qg0MAtU117QcKxBlHIPGt55j8/BFNZe8BJ9pDhHyr8TlbvZ5E8auh1e5jk/X1x3VELZXuaN92qBOr/36qvI+njjQiMGFgCA4JrK2DEk1r5lWG+vKSHEBUaVv5nfbWaP5L+G79iwFQkh1sV6k/nTAF4B4DoARwB8PBq4snFc9CueEKI660pmdz/m7l3vZ+dnAdywytiXGsdFbVeEENVZV3a92DQu560AHo3GCiGGw5pqdt5r6g0AdprZIQAfBPAGM7sOfbHzGQDvGmRjIyMjuOZnry3ElxdnC7FOh9u2dgLRMLIpHR0tqsudoEFXr8XjdO5AzY7W0S2hVHpQpdsLDBsiuqxW2vg6aqSGHYj2J6ibZ6o/gPYyr6fPxsYKsU6H72Ob2N7248W1LAfba7VeoPHpad5obg/Zpo1wtT0675HKzZrSUYW7BOvtNfW5SlsVQmw4+iNWiERQMguRCEpmIRJBySxEIgzVaWRqagqv/9VfKcSPP19sIPbs00/QOebO8crSep3vSpYVf15lQe1uLbCbZU4ZnnGVMlJ0I6gdbi9Q1cm+AKvYvBI1Owuf9UdOI8XxUe0zgnVECjqr5e50okZrfJtjxK2kHpzHs2d4A7sTx7hN876rry7Epqen6dheIERH7wyA2iCrcZwQAkpmIZJBySxEIiiZhUiEoQpgzWYTl19xRSE+2iz+4X/06I/oHM8dOkPj09u203ijUSy/i0SJyBaViWtZqAHxL4Q/NYmwE0pU4dyRcDK4eWuZnkhRr6lIhIwuMyZE1gIRqB7Y9WZEiFyc50YG584Wy4YBYG72SRqf2rGrENu+nV9nEzt43IKy3y4TCyNhcUB0ZxYiEZTMQiSCklmIRFAyC5EISmYhEmGoanbPHUvtpUL83LmzhVikrkZN0sp0rl9aKq4BAFotrmaPjxebwQWVlegGxgcR0boZHr0AH8Sd1Bh2A1teVvYazx1YAQeN7UCazwHRsQoarQX3HVY+2w5MJqaneCnmwgK/Hn78zLOF2FXXXkPHjk9vo3ELVHgnT06YYUEZdGcWIhGUzEIkgpJZiERQMguRCIM0jttvZt8ws8fN7DEze08enzGz+83syfx/dbUQYgsZRM3uAHifu3/PzKYAfNfM7gfwewAecPc7zOx2ALcDeP9qE7k7uqQuemmxaKu7cG6OzjExMUHjjUA1ZLarrSVemx0J0U5U2ki1juq7QyvWEi+phxXYUaM5plBHTdyCt+vZzGHteFSvHqjZdI/KlieTYzUywpu7Nes8XgsMGxqk7tsjxTlQ8msNnmLsOvHoAA7III3jjrj79/KPzwE4COAyADcDOJAPOwDgLZVWIoSoRKm/mc3sSgC/COBBAHvc/Uj+paMA9mzoyoQQpRg4mc1sEsBXALzX3V/2Lpn3KzPo7wgrG8ctzPNfnYUQ1Rkomc2sgX4i/727fzUPH3ux51T+/3H2vSsbx41P8AbqQojqDNJrytBvR3PQ3T+x4kv3AbgFwB35//euNVeWGcZHi/2FaMklEcUAhA6Q4cv1ncElnHoteIneivFuoNR0ieMkANQCgaTeDJpnEVpLvIdSRH2s2GcrEtc6wXGlbqPBHLXg+DEXzvwrQbxIVG5arxVFLQvEvFarReORaDlJzBaYUysQu3NGQmmXtDeuaM45kJr9ywB+F8APzOzhPPYB9JP4S2Z2K4BnAby92lKEEFUYpHHctxA/FXnjxi5HCLFeVAEmRCIomYVIBCWzEIkwVHMCuKPTKSqKzHBgbi4o5wxK9UYbRZUcALxbLN2s14PyR6JaA7ycM2rZFKnF3UBtb4KUDJIeUeshUoDLUKbcNDRaCBQXNtwCcb8xws8NK8XsLEV9s/jcZY53dEyjfZ9f4k9lFknNxdQIv4YHRXdmIRJBySxEIiiZhUgEJbMQiaBkFiIRhqpmW2ZojDQKcaYQeourg/UmX/IYaRAHAF3yMvn4OFfEF9u8RrfdKyri3g3qkwPpNnrtvN0p1ltHajF7WR6I68Rby2R/ArU4NEQgHfJYXfHq8I0aOe8WHL9eKDgX1+dZUH8eHKflwHCg2ymOD8q4MRIp0Qu8iR1/l0BWu0IIKJmFSAYlsxCJoGQWIhGUzEIkwnBrs2EwUks7MlJUouuBOm2RMhoV3hILiCywmx2p8222iZQaOUhESmpUoNwjjdx6gVpcD+a2wOGDHZPQkSWIg8TL2AYDgIevww/OctDsr9cmTyvGuD1VPair7rYGt15mCjwQWxWPjhbdXvqTF2XxqkdJd2YhEkHJLEQiKJmFSAQlsxCJMIjV7n4An0e/Y4UD+Iy7f9LMPgTg9wG8kA/9gLt/fbW53PkL6c2x8UJsx85ddI7506dp/NxZbmbASvKi4koLxaviz7yMlDkCqwhxwdz8nXY+d2RlWyeWsNFaqHUuuEEEwIUxj8oOA2ExumXwYxWIaJHxAaEWmEx0iVEFANSDMtnL9l9RiE1OTdOxS0vcxtcDobRBzlkWnINBqdI4DgDudPePVVqBEGJDGMRq9wiAI/nH58zsxcZxQogLiCqN4wDg3Wb2iJndFfVnXtlral69poTYNKo0jvs0gFcAuA79O/fH2fet7DU1oV5TQmwa624c5+7H3L3r7j0AnwVww+YtUwixFutuHGdme1f0Z34rgEfXmsvhWOoUFcWZ3bsLsSuvuZbO8ciD36bx06fO0vj4eFEpb5LmdQDQJqWVAOBZUUmNqh8jPTJ66R60PDCyMgjKEQPFNCMKeo+q+4AHKje1lg1U69i0gKvFWY2YUvTKPSWoNUlzPDJv/gUa3rNvH49fVpSGxsb4tdMKjC3CcxnsZxWqNI57p5ldh/5qnwHwrg1fnRBiYKo0jlv1mbIQYrioAkyIRFAyC5EISmYhEmGo5gTujhZRs6emtxVi+66+ks6xcG6Wxn/8fz+k8VqJxmfNWtEGGADADASCWuGs5Mv/zKwhmiPqfBbNzeqwo9psC16uz+rEDjfswBasO6h9ZvN0gvXVAiWa2Q8ze2UAWGrz+umx6CkBUeejRnDWDBT74HbppA5b5gRCCABKZiGSQcksRCIomYVIBCWzEIkwXDUbTpXXReLSsG1mhs5x9StfSeNNUqMLAM89/Uxxe0Ezr0aDq9l1cpjaQRV2LZAkOz2upJoTK2CicAN9lwhGWOVLjnWtFqiuDb5NI64iYZ10FjieBLXSHWJx2w1qnJtNboNcI3Jxo8kbA+6amKLxHTPc1WZkjGzTAheY0CGFu5uwcxMp34OiO7MQiaBkFiIRlMxCJIKSWYhEGG6vKQc6naKg0uksF2IWvOi+bWfRyAAA9gc2tD0iTDx58Ak6dmmZi1SsdHOxVVwzsEofpkAZYzavtUAwokYBAEIJjGySGQIAQOAcjF6vKEhF5ZI9CyS6TtCfiVwLjYyLkM2gD1iNHL9tgR3u3v2X0/juS/fSeDaxvRCrB+Kkk+MEAB71DSPCJyvtLYPuzEIkgpJZiERQMguRCEpmIRJhzWQ2s1Ez+7aZ/Y+ZPWZmf5HHrzKzB83sKTP7opnxshshxFAYRM1eBnCju8/l/tnfMrN/BvAn6PeausfM/gbAregb44e4A13S6b7dLarIzaAkb2xygsYnJ7nBfrtdLLt0oiQCwIkjx2h8bq7YiWN2jpeEdpyX7zHL3z6suVtkfMBniMwJMtJAzYMy1MgiOKPGAoGRQWQ/HBo2FGOjQdlmuE2yvqlp2lwF2y/ZSePTl/AnJE7Ke9ttfn6jcxb2ESRPN4JK0YFZ887sfV68mhv5PwdwI4Av5/EDAN5SbSlCiCoM2tGilntmHwdwP4AfAjjj7i8+XDsENZMTYksZKJnzNjTXAdiHfhsa/uoSYWXjuIWF+XUuUwixFqXUbHc/A+AbAF4HYNrspT/K9gE4HHzPS43jxsf537tCiOoMombvMrPp/OMxAG8CcBD9pH5bPuwWAPdu1iKFEGsziJq9F8ABM6uhn/xfcvd/MrPHAdxjZh8B8H30m8utCasvrvWKy7CgOVl7mdfAtslL9AAwPl2s033Fz/OX1Hfv30/jLxw/XohNHr2Ejm0tLtF4L3jp/vTJU4VYZIfbDOxcOx0+d5aRuuqwuRsnIxJ1PaifjlT1TrDvbfJkY3KKP5UYD55i7Nl7aSG2a88eOrY5yg0sFpb5k4nRRnEtjsBswIInEKX8c8udm/MZpNfUI+g3WD8//jTUxlWICwZVgAmRCEpmIRJBySxEIiiZhUiEoTqNmHE1OyP2r71AGV1Y5I274o0W5x6f5KpmpJiOE4V178/so2MXg/WdOnGSxse2F90sZmd5c7wsEDsj9bvrRRW51eJuKpEizjbJZwAWAiU/cl/Zf/lVhdjO3fwpwbYd3D1keqZYh71zN6+1jpr9sWaGAD+XFhRQZ1Hbt6g2m+TBptdmCyEuDpTMQiSCklmIRFAyC5EIw+015VzYigSScnMH6gGxlm1HQ4M+TNt2FPteNXZHJY187pndZ2j81KliOef8PH+7rLvI7X0jUavVKcbjl+u5iMb2x8CPU6vFRbSZGW4KcOmlxVLMyMQh6oXFJLqszs9NI5ijuxCZJxTnrhFBdXX43Oyazyrmge7MQiSCklmIRFAyC5EISmYhEkHJLEQiDLecE7y6jSl7UTln1DwtUrONbDEaGyq9xM61Fai/9To/pGPb+Ev308RydXxbscQTACywc223ucrNyhc9eAE+qiTkajZXi2u1oOlbg9vnjjSKZbX1wIAhqnVstYolpPOL3Gyg0eFzR83doicTlGB9YSNBEq9Yzak7sxCpoGQWIhGUzEIkgpJZiESo0jjubjP7kZk9nP+7bvOXK4SIqNI4DgD+1N2/vMr3vhwD7aTF1OWw1jogUrkZHqjCvUBP7PWK8ehF9+VlrixHqmaN2NZOTY3RsSOkkVl/7sHr0iPlNlofOw29oMucO1eL20HNNnt6EB2/RpNfqg12TIxvr9uN4nyHaK1+cJllVu6X3LLX9yAMYrXrAFjjOCHEBcS6Gse5+4P5lz5qZo+Y2Z1mRh8mvqzXVPA2kBCiOutqHGdmrwbwZ+g3kPslADMA3h987096TU2o15QQm8V6G8fd5O5H8t7NywD+DupuIcSWst7GcU+Y2d48Zug3Wn90MxcqhFidKo3j/t3MdqGvUT8M4A/Wuwim7JV1H4lcQgbdXn+b5caXmzuq0SVKObHIBYBWl88d1YMbkZ0jFT5U22ukqV9wnFotrkR74Ddbq5MmgoEqHJiHUHU+y6LLml8jy0vcIthRPH5ZUH9uwXmPjjd7S8FKu5i8nCqN426stGUhxIaiCjAhEkHJLEQiKJmFSIShmhOEsHLOYGhUthnFmbATle9ZIFbUWH+skj8GIw2NCSSRwNTucfOETtAriZoTeLDvkRmEsUuEL7AbCHQRTLizWmR7O7ho6UG9aTRHFK8TMa5sT6kILoxFYtlg6M4sRCIomYVIBCWzEImgZBYiEZTMQiSCbcZL0uHGzF4A8Gz+6U4AJ4a28a1B+5gGW72PV7j7rrUGDTWZX7Zhs4fc/fot2fiQ0D6mwcWyj/o1W4hEUDILkQhbmcyf2cJtDwvtYxpcFPu4ZX8zCyE2Fv2aLUQiDD2ZzewmM/tfM3vKzG4f9vY3CzO7y8yOm9mjK2IzZna/mT2Z/79jK9dYFTPbb2bfMLPH84YI78njyeznKk0frjKzB/Pr9otm1tzqtZ7PUJM5tx76FIDfBPAqAO80s1cNcw2byN0AbjovdjuAB9z9WgAP5J9fzHQAvM/dXwXgtQD+MD9/Ke3ni00fXgPgOgA3mdlrAfwlgDvd/RoApwHcuoVrpAz7znwDgKfc/Wl3bwG4B8DNQ17DpuDu3wRw6rzwzQAO5B8fQN/48KIld2T9Xv7xOQAHAVyGhPYzd5xlTR9uBPBi95YLch+HncyXAXhuxeeH8liq7HH3I/nHRwHs2crFbCRmdiX63nAPIrH9PL/pA4AfAjjj/pLT4gV53UoAGxJ5m58kHh2Y2SSArwB4r7vPrvxaCvt5ftMH9Js9XPAMO5kPA9i/4vN9eSxVjq3wF9+L/k/6i5q8eeBXAPy9u381Dye3n8DLmj68DsC02Uu2KxfkdTvsZP4OgGtzZbAJ4B0A7hvyGobJfQBuyT++BcC9W7iWyuQNDz4H4KC7f2LFl5LZz6Dpw0H0k/pt+bALch+HXjRiZm8G8FfoO5Lf5e4fHeoCNgkz+wKAN6D/hs0xAB8E8I8AvgTgcvTfFnu7u58vkl00mNnrAfwHgB/gJ4ZVH0D/7+Yk9tPMfgF9gWtl04cPm9nV6Au2MwC+D+B38tZMFwyqABMiESSACZEISmYhEkHJLEQiKJmFSAQlsxCJoGQWIhGUzEIkgpJZiET4f1wbNOOnoHogAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
